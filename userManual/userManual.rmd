---
title: ""
author: ""
date: ""
output: 
  pdf_document:
    keep_tex: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\section*{User Manual}%\label{Usermanual:usermanual}

An implementation of the model described in the main manuscript is provided as an R script named "model.R". The script
contains functions for the estimation of haplotype frequencies, multiplicity of infection (MOI), and two linkage disequilibrium (LD)
measures, i.e., $D'$ and $R^2$, from a pair of multi-allelic loci. Additionally, the code in the script "tutorial.R" serves as 
template for deriving the estimates from empirical data. 

The scripts and some example datasets can be found on GitHub (\url{https://github.com/Maths-against-Malaria/generalModel}).

\subsection*{Loading the R script}

Suppose the main R script is stored in a directory
"$<$PATH$>$/STRModel.R".  First, the script has to be loaded in the R environment (e.g., R
Studio, VS Code, or an R terminal) using the following code:

```{r}
# Load external resources
    source("/Users/christian/Documents/phd/models/generalModel/src/model.R")
```

Here, we assume that the $<$PATH$>$ containing the R script is "/home/johndoe/Documents/".

\subsection*{Importing data}
A dataset needs to be imported first (see below for the required format). Assume the dataset "example\_dataset1.xlsx" (provided with the script)
is downloaded and stored in the folder "Documents" whose path is given by "/home/johndoe/Documents/". The dataset can be imported using the R
package "openxlsx". However, the package is not present by default and might need to be installed using the following code:

```{r}
# Install library "openxlsx"
    #install.packages("openxlsx") 
```

The library is then loaded upon successful installation and the data
imported using the code:


```{r}
# Load library "openxlsx"
library(openxlsx)
```

A more comprehensive documentation exists as a guide to use the package
"openxlsx". Note that other packages can be used to import ".xlsx"
files in R and represent a good alternative to the "openxlsx" package
described above. Moreover, functions such as "read.csv" and
"read.table" can be used to import data in the ".csv" and ".txt"
formats, respectively.


\subsection*{Standard input format and data transformation}

The methods are designed for data containing information from a pair
of multi-allelic markers, e.g., microsatellites markers with
$n_1$ and $n_2$ alleles, respectively. First, the desired data format is explained. Second, it is explained how custom data can be converted into this format.

For each record (corresponding to one sample) the data indicates the absence and presence of the alleles found at both molecular markers, in the following convention. At marker $k$, the absence and presence of the alleles correspond to a 0-1 vector of length $n_k$ $(k=1,2)$. This corresponds to a binary number between 0 and $2^{n_k}-1$, where the vector $\pmb 0= (0,\ldots,0)$ corresponds to missing data, $(1,0,\ldots,0)$ indicates the presence of the first allele, and $(1,1,\ldots,1)$ indicates the presence of all alleles.

A dataset of sample size $N$ is an array  with $N$ rows in which the entries are numbers from 0 to $2^{n_1}-1$ and 0 to $2^{n_2}-1$ at the first and second marker,
respectively. As an example, the following dataset of sample size $N = 100$, with
$n_1 = 2$ and $n_2 = 3$ alleles at the first and second marker has the correct format:

\begin{table}[tbh]
\begin{center}
\begin{tabular}[5cm]{|l|c|c|}
\hline
ID & Marker1 & Marker2\\
\hline
ID1 & 3 & 7\\
\hline
ID2 & 2 & 5\\
\hline
ID3 & 1 & 2\\
\hline
$\vdots$ & $\vdots$ & $\vdots$\\
\hline
ID99 & 0 & 0\\
\hline
ID100 & 0 & 3\\
\hline
\end{tabular}
\end{center}
\label{tab:table1man}
\end{table}

Absence/presence of alleles at the first marker
are encoded by numbers from 0 to $2^2 - 1 = 3$, and by numbers from 0 to $2^3 - 1 = 7$ at the second marker. For the second record (ID2) the number 2 at the first marker corresponds to the 0-1 vector (0,1), indicating the absence of the first and presence of the second allele, while the entry 5 at marker 2 corresponds to the 0-1-vector (1,0,1) that represents the presence of only the first and third allele. For the last record (ID100), entry 0 at marker 1 corresponds to the vector (0,0) indicating missing data, while entry 3 is equivalent to the 0-1 vector (1,1,0), indicating the presence of the first and second alleles.

This format is referred to as \textbf{\textit{standard input format}}. The ID column in the dataset is optional and can be
omitted.

If data is not present in the format outlined above, it needs to be transformed. This can be done easily if the data is already in the following `more natural' format, for which each record (sample) is represented by multiple \textbf{consecutive} rows, which list the alleles found at the respective markers. The first column has to contain the sample ID.

Assume a dataset with four molecular markers and the STR alleles (corresponding to distinct sequence lengths): (i) 130, 133 at marker 1; (ii) 201, 207, 210 at  marker 2; (iii) 89, 91, 94, 99 at marker 3; and (iv) 140, 145, 148 at marker 4. Assume the following structure:

\begin{table}[tbh]
\centering
\begin{tabular}[5cm]{|l|c|c|c|c|}
\hline
ID      & M1   & M2   & M3  & M4  \\
\hline
ID1     & 130  & 207  & 99  & 140 \\
\hline
ID1     & 133  & 201  &     &     \\
\hline
ID1     &      & 210  &     &     \\
\hline
ID2     & 133  & 201  & 99  & 140 \\
\hline
ID2     & 133  & 210  & 91  & 145 \\
\hline
ID3     & 130  & 207  & 91  & 148 \\
\hline
$\vdots$ &  $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$\\
\hline
ID99    &      &      & 89  & 145 \\
\hline
ID99    &      &      & 99  & 148 \\
\hline
ID100   &      & 201  & 94  & 148\\
\hline
ID100   &      & 207  &     & 140\\
\hline
\end{tabular}
\label{table2man}
\end{table}
Consider sample ID1. The two alleles 130 and 133 correspond to the 0-1 vector (1,1) at marker 1, the three alleles 201, 207, and 210, to (1,1,1) at marker 2, the allele 99  to (1,0,0,0) at marker 3, and the allele 140 to (1,0,0) at marker 4.

The function "data\_format(<DATA>, id=TRUE)" takes the data in this `more natural' format and creates a list as an output, with the data transformed into the standard input format as the first element. The second element is a list, which contains a string vector with the alleles occurring at each marker. The third element contains a vector with the number of alleles found at each marker.
The optional boolean argument "id" (default id=TRUE) indicates whether the transformed dataset in the standard input format should contain the sample ID in the first column. The following code first imports the data "/home/johndoe/Documents/example\_dataset4.xlsx" into "DATA1", transforms it into the standard input format, and saves the output list as  "Ex.data":

```{r, results='hide'}
## Import the dataset
datasetNaturalFormat <- read.xlsx('/Users/christian/Documents/phd/models/generalModel/exampleDatasets/exampleDatasetNaturalFormat.xlsx', 1)

# Transform the data to the standard format
datasetStandard <- convertDatasetToStandardFormat(datasetNaturalFormat, 2:ncol(datasetNaturalFormat))
```

\begin{verbatim}
##  $ Ex.data
##  [[1]]
##  ID    M1   M2   M3   M4
##  ID1    2    4    4    4
##  ID2    2    4    2    1
##  ID3    1    4    2    1
##  ...    ...  ...  ...  ...
##  ID98   2    4    2    1
##  ID99   3    4    4    5
##  ID100  1    5    4    4

##  [[2]]
##  [[2]]$M1
##  [1] "130" "133"

##  [[2]]$M2
##  [1] "201" "207" "210"

##  [[2]]$M3
##  [1] "89" "91" "94" "99"

##  [[2]]$M4
##  [1] "140" "145" "148"

##  [[3]]
##  M1 M2 M3 M4
##   2  3  4  3
\end{verbatim}

The first element of the above list is in the desired standard input format but contains more than 2 markers.

If data is given in a different format, the R-package \textbf{MLMOI} provides a flexible function to import the data into this format. This package also helps to detect data entry errors. To install the package, load it and access the documentation type

```{r}
# Install library "MLMOI"
#install.packages("MLMOI")

# Load library
#library("MLMOI")

# Consult documentation
?MLMOI
```

\section*{Haplotype frequencies and MOI estimates}
Assume that the script "STRModel.R" and the data set $<$DATA$>$ were loaded (see above).

The function "mle($<$DATA$>$, $<$n1n2$>$,$\ldots$)" derives the maximum likelihood estimates (MLEs) of the 2-marker haplotype frequencies and the MOI parameter. The arguments are the dataset in standard input format ($<$DATA$>$), and a vector containing the number of alleles at the first and second marker ($<$n1n2$>$) and several optional arguments.

If $<$DATA$>$ does not contain sample IDs in the first column,
the argument "id = FALSE" must be specified.

The output of the function "mle($<$DATA$>$, $<$n1n2$>$,$\ldots$)" is a list with three elements: (i) the MOI parameter $\hat \lambda$; (ii) the non-zero haplotype frequencies $\hat p$; and (iii) a matrix of all detected haplotypes with estimated non-vanishing frequency. Alleles at marker $k$ are denoted by the numbers $0,\ldots,n_k-1$ ($k=1,2$).

```{r}
## Choose markers of interests
markers <- 1:4
calculateMaximumLikelihoodEstimatesWithAddOns(datasetStandard[[1]][,markers], datasetStandard[[3]][markers], idExists = FALSE)
```

As an additional example, consider the list  "Ex.data". The data set in standard input format is contained as first element, but contains information from 4 markers. Suppose the estimates are desired for data from markers 3 and 4. The following code provides the estimates:

```{r}
### Selecting the data without the column for sample IDs:
#data <- Ex.data[[1]][,c(4,5)]
### Selecting the number of alleles at markers 3 and 4:
#GA <- Ex.data[[3]][c(3,4)]
### Estimating the MLEs
#mle(data, GA, id = FALSE)
```

\section*{Haplotype frequencies using a plug-in estimate for MOI}

The function "mle($<$DATA$>$, $<$n1n2$>$,$\ldots$)" allows to derive the MLEs for haplotype frequencies using a plug-in value for the MOI parameter (e.g., it has been independently estimated), i.e., the function provides the profile-likelihood estimates for haplotype frequencies given a fixed value for the MOI parameter. The argument
"plugin=$\hat \lambda_\text{plugin}$" specifies that
$\hat \lambda_\text{plugin}$ should be used as plug-in estimate for the MOI parameter.

Consider the data "example\_dataset1.xlsx" (with $n_1=2$ and $n_2=3$ allels for marker 1 and 2, respectively). Assuming the plug-in
$\hat \lambda_\text{plugin} = 0.2$ for the MOI parameter, MLEs for the haplotype frequencies are obtained by running the code:

```{r}
calculateMaximumLikelihoodEstimatesWithAddOns(datasetStandard[[1]][,markers], datasetStandard[[3]][markers], idExists = FALSE, pluginValueOfLambda = 1.0)
```

\section*{Bias-corrected estimates}

Biased corrected estimates can be obtained by setting the option "BC =
TRUE" (default "BC = FALSE"). The default is a bootstrap bias correction
(default "method=`bootstrap' ") based on $10\,000$ bootstrap replicates (default "Bbias $= 10\,000$"). Alternatively, a jackknife bias correction can be
obtained by setting the option "method=`jackknife' ". (The jachknife bias-correction ignores the optional argument "Bbias".)

The following code provides the bias-corrected MLEs for the dataset DATA based on $15\,000$ boostrap replicates:

```{r}
calculateMaximumLikelihoodEstimatesWithAddOns(datasetStandard[[1]][,markers], datasetStandard[[3]][markers], idExists = FALSE, isBiasCorrection = TRUE, methodForBiasCorrection = "bootstrap", numberOfBootstrapReplicatesBiasCorrection = 15)
```


The bias-corrected MLEs with the `jackknife' method and a plug-in value of the MOI parameter are obtained as follows:

```{r}
calculateMaximumLikelihoodEstimatesWithAddOns(datasetStandard[[1]][,markers], datasetStandard[[3]][markers], idExists = FALSE, pluginValueOfLambda = 1.0, isBiasCorrection = TRUE, methodForBiasCorrection = "jackknife")
```

\section*{Bootstrap confidence intervals}

Moreover, equally-tailed $(1-\alpha)\times 100$\% bootstrap-percentile confidence intervals (CIs) \cite{EfronTibshirani1994} are outputted alongside the
estimates if the option "CI = TRUE" is specified (default "CI=FALSE"). The default are $B=10\,000$ bootstrap repeats (default "B=$10\,000$") and $\alpha=0.05$ (default "alpha=0.05"). In this case, the MOI parameter estimate is a vector that contains the MLE, and the upper and lower confidence points, except a plug-in estimate is provided. The haplotype frequencies are provided as an array with 3 columns, where the first column provides the estimates, and the second and third the upper and lower confidence points, respectively.

To obtain the estimates of the MOI parameter and haplotype frequencies with their corresponding $95\%$ confidence intervals based on $15\,000$ bootstrap replicates, one should run the following code:

```{r}
calculateMaximumLikelihoodEstimatesWithAddOns(datasetStandard[[1]][,markers], datasetStandard[[3]][markers], idExists = FALSE, isBiasCorrection = TRUE, methodForBiasCorrection = "bootstrap", numberOfBootstrapReplicatesBiasCorrection = 15, isConfidenceInterval = TRUE, numberOfBootstrapReplicatesConfidenceInterval = 10)
```

The following code provides the estimates with 90\% CIs based on $20\,000$ bootstrap repeats:

```{r}
calculateMaximumLikelihoodEstimatesWithAddOns(datasetStandard[[1]][,markers], datasetStandard[[3]][markers], idExists = FALSE, isBiasCorrection = TRUE, methodForBiasCorrection = "bootstrap", numberOfBootstrapReplicatesBiasCorrection = 15,  isConfidenceInterval = TRUE, numberOfBootstrapReplicatesConfidenceInterval = 20, significanceLevel = 0.1)
```

\section*{Linkage disequilibrium estimates}

The function ld($<$DATA$>$,\ldots) derives LD measures from the output of the function  mle($<$DATA$>$,\ldots). The function outputs the four LD measures $D'$, $r^2$, $Q^\ast$, and the ALD measures $W_{A|B}$ and
$W_{B|A}$. Moreover, the option to output the ($1-\alpha$)-level
bootstrap confidence intervals for the LD estimates or bias-corrected
estimates are available and are used as with the function
mle($<$DATA$>$,\ldots). Estimation of LD with a $95\%$ confidence
interval is done in the following code snippet:

```{r}
markersPair <- c(4,4)
calculatePairwiseLDWithAddons(datasetStandard,markersPair, idExists = FALSE)
```

```{r}
calculatePairwiseLDWithAddons(datasetStandard,markersPair, idExists = FALSE, isConfidenceInterval=TRUE,numberOfBootstrapReplicatesConfidenceInterval=100, significanceLevel=0.05)
```

<!-- \section*{Generating simulated data} -->

<!-- Simulated data can be generated using the function -->
<!-- "datasetgen(P,lambda,N,arch)". The required arguments are the -->
<!-- haplotype frequency distribution $\pmb{p}$ of length $2^n$, the MOI -->
<!-- parameter $\lambda$, the sample size $N$, and a list $arch$ -->
<!-- containing the number of alleles at the first and second locus, -->
<!-- respectively. For example, when considering $n_1=3$ and $n_2=2$ -->
<!-- alleles at the first and second locus, respectively, haplotype frequency -->
<!-- distribution $\pmb{p} =(0.25,0.15,0.20,0.10,0.20,0.10)$, MOI parameter -->
<!-- $\lambda=0.2$ a dataset of sample size $N=100$ is generated with the -->
<!-- following code: -->

<!-- ```{r, results='hide'} -->
<!-- # Generate dataset -->
<!-- datasetgen(c(0.25,0.15,0.20,0.10,0.20,0.10), 0.2, 100, c(2,3)) -->
<!-- ``` -->

<!-- The output (not shown here,) is a random $N \times n$ matrix with -->
<!-- entries corresponding to the data structure described above. -->

<!-- Regarding the frequency vector $\pmb{p}$, the haplotypes have to be in -->
<!-- a specific order. The required order is obtained by the function -->
<!-- "hapl($arch$)". The function outputs a $n_1 n_2\times 2$ matrix -->
<!-- with entries 0 to $n_1 - 1$ at the first locus and 0 to $n_2 - 1$ at -->
<!-- the second.Each row can be interpreted as the mix-radix representation -->
<!-- (plus one) of the index of the haplotype in the base $(n_1, n_2)$. For -->
<!-- example, for $n_1=3$ and $n_2=2$ loci the code outputs the -->
<!-- representation of all 4 possible haplotypes: -->

<!-- ```{r} -->
<!-- hapl(c(2,3)) -->
<!-- ``` -->

<!-- This indicates that haplotype (0,0) is represented by 1, haplotype (0,1) -->
<!-- by 2, haplotype (1,0) by 3, haplotype (1,1) by 4, and so on. Hence, in -->
<!-- the above code example $\pmb {p} =(0.25,0.15,0.20,0.10,0.20,0.10)$ -->
<!-- indicates that haplotype (0,0) has frequency $p_1=0.25$, haplotype -->
<!-- (0,1) has frequency $p_2=0.15$ haplotype (1,0) has frequency -->
<!-- $p_3=0.2$ haplotype (1,1) has frequency $p_4=0.1$, and $p_5$, -->
<!-- $p_6$ have frequency 0.20 and 0.10, respectively. -->
